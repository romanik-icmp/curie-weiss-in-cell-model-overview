\documentclass[12pt]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{hyperref} % for hyperlinks in references
\usepackage[notref,notcite,color]{showkeyskay}\definecolor{labelkey}{rgb}{1,0,0.5}

\usepackage{graphicx}
\usepackage{caption} % for \caption*
\usepackage{mdframed} % for framed text and formulas
\usepackage[dvipsnames]{xcolor}

\numberwithin{equation}{section}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\e}{\mbox{e}}
\newcommand {\mm}[1]{\quad\mbox{#1}\quad}
\newcommand {\MM}[1]{\qquad\mbox{#1}\qquad}

\textwidth 180mm
\textheight 230mm
\voffset = -20mm
\hoffset = -10mm

\title{Overview: a cell fluid model with Curie-Weiss interaction}

\author{R.V.~Romanik
	\\ \small Institute for Condensed Matter Physics, NAS of Ukraine
	\\ \small 1~Svientsitskii Street, 79011, Lviv, Ukraine
	\\ \small romanik@icmp.lviv.ua}
%\author{R.V.~Romanik \\ Institute for Condensed Matter Physics, NAS of Ukraine}

\begin{document}
	\allowdisplaybreaks
	
	\maketitle
	
	%\begin{multicols}{2}
	
	\abstract{Review of the cell fluid model with Curie-Weiss interaction.
		\\	
		\textbf{Keywords:} Cell fluid model, Curie-Weiss interaction.
	}
	
	\tableofcontents
	
	\section{Introduction}
	The cell model was introduced and described in~\cite{KKD18,KKD20}. This model possesses an exact solution in the case of Curie-Weiss interaction. The exact asymptotic (in the thermodynamic limit) expression for the grand partition function was obtained in~\cite{KKD20}.
	The goals of this manuscript are to (a) summarize the known results; (b) standardize the notation; (c) properly account for quantity dimensions corresponding to physical problems; (d) account for the thermal de Broglie wavelength in the definition of the grand partition function, in order to properly account for temperature dependence while calculating the entropy; and (e) calculate the entropy.
	
	\section{\label{sec:model} Model}
	Let us briefly introduce the model, notation, and summarize the known results for the model.
	
	The main results are obtained within the formalism of the grand canonical ensemble. An open system of point particles is considered in volume $V$. The total volume $V$ is divided into $N_v$ congruent cubic cells $\Delta_l$ of volume $v=c^3$ each, such that the volume $V$ is the union of all $\Delta_l$
	\begin{equation*}
		V = \bigcup_{l=1}^{N_v}\Delta_l,
	\end{equation*}
	and for each pair of $\Delta_l$ and $\Delta_{l'}$
	\begin{equation*}
		\Delta_l \cap \Delta_{l'} = \emptyset, \text{ if } l \neq l'.
	\end{equation*}
	
	\textbf{Interaction.} Consider a configuration of particles $\gamma = \{\vb{r}^N\}$, where $\vb{r}^N \equiv \vb{r}_1, ..., \vb{r}_N$, $\vb{r}_i$ is the space coordinate of the $i$-th particle and $N \equiv \abs{\gamma}$ is the number of points (particles) in the configuration $\gamma$. The potential energy of interaction between particles in $\gamma$ is defined as follows (cf.~\cite[eq.~(2.5.16)]{HansenMcDonald13})
	\begin{eqnarray*}
		W_{N_v}(\vb{r}^N) & = & \frac{1}{2} \sum_{\vb{r}_i,\vb{r}_j \in \gamma} \Phi_{N_v} (\vb{r}_i,\vb{r}_j)
		\\
		& = & \frac12 {\sum_{i=1}^N \sum_{j=1}^N} \Phi_{N_v} (\vb{r}_i,\vb{r}_j),
	\end{eqnarray*}
	where $\Phi_{N_v}$ is given by the Curie-Weiss interaction
	\begin{equation}
		\label{def:curie-weiss-pot}
		\Phi_{N_v}(\vb{r}_i, \vb{r}_j) = -\frac{J_1}{N_v} + J_2\sum_{l=1}^{N_v} \mathbb{I}_{\Delta_l}(\vb{r}_i) \mathbb{I}_{\Delta_l}(\vb{r}_j),
	\end{equation}
	and $\mathbb{I}_{\Delta_l}(\vb{r})$ is the indicator of $\Delta_l$
	\begin{equation}
		\label{def:I}
		\mathbb{I}_{\Delta_l} (\vb{r}) = \left\{
		\begin{array}{ll}
			1, \quad \vb{r} \in \Delta_l,
			\\
			0, \quad \vb{r} \notin \Delta_l.
		\end{array}
		\right.
	\end{equation}
	The first term in $\Phi_{N_v}$ describes the pairwise attraction between all particles and is characterized by $J_1 > 0$. The second term in $\Phi_{N_v}$ describes the repulsion between two particles contained within the same cell $\Delta_l$ and is characterized by $J_2 > 0.$ For convenience, in $W_{N_v}$ above the self-interaction term $\Phi_{N_v}(\vb{r},\vb{r})$ is included, which does not affect the physics of the model. Two cases are possible for $\Phi_{N_v}(\vb{r}_i, \vb{r}_j)$, either two particles belong to the same cell or to different ones. Explicitly, one has
	\begin{equation}
		\Phi_{N_v}(\vb{r}_i, \vb{r}_j) = \left\{
		\begin{array}{ll}
			-\frac{J_1}{N_v} + J_2, & \text{when particles are in the same cell,}
			\\
			-\frac{J_1}{N_v}, & \text{otherwise.}
		\end{array}
		\right.
	\end{equation}
	
	\textbf{Stability.} For stability of interaction the following condition must hold
	\begin{equation*}
		J_2 > J_1
	\end{equation*}
	to satisfy the following inequality~\cite{KKD20,Ruelle70}
	\begin{equation}
		\int_{V} \Phi_{N_v}(\vb{r},\vb{r}') {\rm d} \vb{r}' > 0, \quad \text{for all } \vb{r} \in V.
	\end{equation}
	Note that there is one contribution to this integral from a cell containing the coordinate $\vb{r}$, and $(N_v - 1)$ contributions from the other cells:
	\begin{eqnarray*}
		\int_{V} \Phi_{N_v}(\vb{r},\vb{r}') {\rm d} \vb{r}' & = & \left(-\frac{J_1}{N_v} + J_2\right)v - (N_v - 1) \frac{J_1}{N_v}v
		\\
		& = & (J_2 - J_1)v > 0.
	\end{eqnarray*}
	The ratio of the two energy constants is denoted by
	$$a = J_2/J_1,$$
	and thus $a > 1.$
	
	\textbf{The grand partition function} (GPF) is expressed as follows~\cite[see eqs.~(2.4.6) and~(2.3.13)]{HansenMcDonald13}
	\begin{equation}\label{ZGR}
		\Xi=\sum_{N=0}^{\infty}\frac{\zeta^N}{N!}Z_N,
	\end{equation}
		where $\zeta$ is the activity
	\begin{equation*}
		\zeta = \frac{\exp(\beta \mu)}{\Lambda^3},
	\end{equation*}
	$\beta = 1/(k_{\rm B} T)$ the inverse temperature, $k_{\rm B}$ the Boltzmann constant, $T$ the temperature, $\mu$ the chemical potential, $\Lambda = (2\pi\beta\hbar^2/m)^{1/2}$ the de Broglie thermal wavelength~\footnote{The presence of $\Lambda$ in~\eqref{ZGR} arises from (a) the choice of the normalization factor in the definition of the partition function, ensuring consistency between classical and quantum statistical mechanics, and (b) the integration over momenta (see, e.g.,~\cite[Section~2.3]{HansenMcDonald13})}, $\hbar$ the Planck constant, $m$ the mass of a particle. The configuration integral $Z_N$ is defined as
	\begin{equation}
		Z_N = \int\exp(-\beta W_{N_v}(\vb{r}^N)){\rm d}\vb{r}^N
	\end{equation}
	with ${\rm d} \vb{r}^N \equiv {\rm d}{\vb r_1} \dotsc {\rm d}{\vb r_N}$.
	In the GPF the integration goes over all configurations $\gamma$ with $N$ particles and then the summation goes over all positive integer values of $N$.
	
	\textbf{Reduced quantities.} Natural units for energy and length in the model are $J_1$ and $c$, respectively. It is standard practice to express thermodynamic results in terms of dimensionless quantities normalized by these natural units. The advantage of using such quantities is that their numerical values are typically of the order of unity, which simplifies analysis. 	For any dimensional quantity $Q$, it is convenient to denote its dimensionless, or so called 'reduced', counterpart by $Q^*$. Thus, we introduce the following reduced quantities:
	%the reduced temperature $T^* = k_{\rm B} T / J_1$, the reduced inverse temperature $p = \beta J_1$, reduced chemical potential $\mu^* = \mu / J_1$, and the reduced pressure $P^* = Pv/J_1$.
	\begin{eqnarray}
		\label{def:reduced}
		T^* := \frac{k_{\rm B} T}{J_1} & \quad & \text{ -- the reduced temperature;} 
		\nonumber\\
		\beta^* \equiv p := \beta J_1 = \frac{1}{T^*} & \quad & \text{ -- the reduced inverse temperature;}
		\nonumber\\
		\mu^* := \frac{\mu}{J_1} & \quad & \text{ -- the reduced chemical potential;}
		\nonumber\\ 
		P^* := \frac{Pv}{J_1} & & \text{ -- the reduced pressure;}
		\nonumber\\
		S^* := \frac{S}{k_{\rm B} \langle N \rangle} & & \text{ -- the reduced entropy;}
		\nonumber\\
		\rho^* := \frac{\langle N \rangle}{V} v && \text{ -- the reduced (particle number) density.}
	\end{eqnarray}
	Here, $\langle N \rangle$ denotes the average number of particles in the system, and in general, $\langle \ldots \rangle$ means averaging over the grand canonical ensemble
	\begin{equation}
		\langle \ldots \rangle = \frac{1}{\Xi} \sum_{N=0}^{\infty}(\ldots)\frac{\zeta^N}{N!}Z_N
	\end{equation}
	\textbf{NOTE}: In previous works~\cite{KKD18,KKD20,KD22}, the following notation was used $p=\beta J_1$. To maintain consistency with other thermodynamic quantities, it may be more conventional to use $\beta^*$ instead of $p$ for the reduced inverse temperature (cf.~\cite{RDGMR13}).
	
	\subsection{Partition function transformation}
	Taking into account the following summation result
	\begin{equation}
		\sum_{\vb{r}_i,\vb{r}_j \in \gamma} 1 = N^2 = \abs{\gamma}^2,
	\end{equation}
	the GPF is explicitly written as
	\begin{equation}
		\label{eq:gpf1}
		\Xi = \sum_{N=0}^{\infty} \frac{\Lambda^{-3N}}{N!}
		\int
		\exp[\beta\mu N + \frac{\beta J_1}{2N_{v}} N^2 - \frac{\beta J_2}{2} \sum_{\vb{r}_i,\vb{r}_j \in \gamma} \sum_{l=1}^{N_v} \mathbb{I}_{\Delta_l}(\vb{r}_i)\mathbb{I}_{\Delta_l}(\vb{r}_j)] {\rm d} \vb{r}^N.
	\end{equation}
	The equation~\eqref{eq:gpf1} can be compared with~\cite[(2.5)]{KKD20}. Coefficients in the exponent under the integral can be represented in a few different forms using dimensionless quantities. For the coefficient in the first term
	\begin{equation*}
		\beta\mu = \beta^*\mu^* = \frac{\mu^*}{T^*},
	\end{equation*}
	for the coefficient in the second term
	\begin{equation*}
		\beta J_1 = \beta^* = \frac{1}{T^*},
	\end{equation*}
	and for the coefficient in the third term
	\begin{equation*}
		\beta J_2 = a \beta J_1 = a \beta^* = \frac{a}{T^*}.
	\end{equation*}
	Since we work in the framework of the grand canonical ensemble, we consider explicitly expressing physical quantities in terms of temperature $T^*$ and chemical potential $\mu^*$ as the most convenient approach. In what follows, we will do so to maintain consistency in notation.
	
	\textbf{GPF transformation}. To rewrite the integrand in~\eqref{eq:gpf1} in a more convenient form we set (cf.~\cite[eq.~(2.7)]{KKD20})
	\begin{equation}
		\label{FNv1}
		F_{N_v}(T^*, \mu^*; \varrho) = \exp[\frac{1}{2T^*N_v}\left(\sum_{l=1}^{N_v} \varrho_l\right)^2 + \frac{\mu^*}{T^*}\sum_{l=1}^{N_v} \varrho_l - \frac{a}{2T^*} \sum_{l=1}^{N_v} \varrho_l^2],
	\end{equation}
	where $\varrho \in \mathbb{N}_0^{N_v}$ is a vector with non-negative integer components $\varrho_l$, $l=1, 2, \ldots , N_v$, i.e. $\varrho = (\varrho_1, \varrho_2, \ldots, \varrho_{N_{v}})$.
	
	For a given $l = 1, \cdots , N_v$ and a configuration $\gamma$, we set $\gamma_l = \gamma \cap \Delta_l,$ that is, $\gamma_l$ is the part of the configuration contained in $\Delta_l$. Then, $N_l \equiv \abs{\gamma_l}$ stands for the number of points (particles) of $\gamma$ contained in $\Delta_l$.
	
	For $\varrho$~\eqref{FNv1}, we substitute the vector $\nu(\gamma) \in \mathbb{N}_0^N$ with components $N_l$ (or $\abs{\gamma_l}$), i.e. $\nu(\gamma)=(N_1, N_2, \ldots, N_{N_v})$ or $\nu(\gamma) = (\abs{\gamma_1}, \abs{\gamma_2}, \ldots, \abs{\gamma_{N_v}})$, and obtain the following expression for the GPF in~\eqref{eq:gpf1}:
	\begin{equation}
		\Xi = \sum_{N=0}^{\infty} \frac{\Lambda^{-3N}}{N!}\int_{V^N} F_{N_v}(T^*,\mu^*;\nu(\gamma)) {\rm d} \vb{r}^N,
	\end{equation}
	which can be compared with~\cite[eq.~(2.8)]{KKD20}.
	
	The next step is to introduce the Kronecker $\delta$-symbol for $n, m \in \mathbb{N}_0$ as
	\begin{equation}
		\label{def:Kronecker}
		\delta_{nm} = \int_0^1 \exp[2\pi {\rm i} t (n-m)] {\rm d}t
	\end{equation}
	and rewrite $F_{N_v}$ as
	\begin{equation}
		F_{N_v}(T^*,\mu^*;\nu(\gamma)) = \sum_{\varrho \in \mathbb{N}_0^{N_v}} F_{N_v}(T^*, \mu^*;\varrho) 
		\int\limits_{[0,1]^{N_v}} \exp[2\pi{\rm i} \sum_{l=1}^{N_v} (\varrho_l - N_l)t_l ] {\rm d} t_1 \ldots {\rm d} t_{N_v},
	\end{equation}
	to arrive at (cf.~\cite[(2.9)]{KKD20})
	\begin{eqnarray}
		\label{eq:XiR}
		\Xi & = &  \sum_{\varrho \in \mathbb{N}_0^{N_v}} F_{N_v}(T^*, \mu^*; \varrho) 
		\sum_{N=0}^{\infty} \frac{\Lambda^{-3N}}{N!} 
		\nonumber\\
		&& \times \int\limits_{V^N} \int\limits_{[0,1]^{N_v}} 
		\exp[2\pi{\rm i} \sum_{l=1}^{N_v} (\varrho_l - N_l)t_l ] {\rm d} t_1 \ldots {\rm d} t_{N_v} {\rm d} \vb{r}^N 
		\nonumber\\
		& = & \sum_{\varrho \in \mathbb{N}_0^{N_v}} F_{N_v}(T^*, \mu^*; \varrho)
		\int\limits_{[0,1]^{N_v}} \exp(2\pi{\rm i} \sum_{l=1}^{N_v} \varrho_l t_l) R_{N_v}(t_1, \ldots, t_{N_v}) {\rm d} t_1 \ldots {\rm d} t_{N_v}.
	\end{eqnarray}
	The summation over $\varrho$ is understood as
	\begin{equation}
		\sum_{\varrho \in \mathbb{N}_0^{N_v}} = \sum_{\varrho_1=0}^{\infty} \ldots \sum_{\varrho_{N_v}=0}^{\infty}.
	\end{equation}
	The quantity $R_N$ is expressed as follows (cf.~\cite[(2.10)]{KKD20})
	\begin{eqnarray}
		\label{def:RN}
		R_{N_v}(t_1, \ldots, t_{N_v}) & = & \sum_{N=0}^{\infty} \frac{\Lambda^{-3N}}{N!} \int\limits_{V^N} \exp(-2\pi{\rm i} \sum_{l=1}^{N_v} N_l t_l) {\rm d} \vb{r}^N
		\nonumber\\
		&=& \sum_{N=0}^{\infty} \frac{\Lambda^{-3N}}{N!} \int\limits_{V^N} \exp(-2\pi{\rm i} \sum_{l=1}^{N_v} \sum_{j=1}^{N} \mathbb{I}_{\Delta_{l}}(\vb{r}_j) t_l) {\rm d} \vb{r}^N,
	\end{eqnarray}
	We used~\eqref{eq:1} to get the last line in the above equation.
	
	Note that the expression under the integral in the last line of~\eqref{def:RN} is factorized in $j$:
	\begin{eqnarray}
		R_{N_v}(t_1, \ldots, t_{N_v}) & = & \sum_{N=0}^{\infty}\frac{1}{N!} 
		\left\{\frac{1}{\Lambda^{3}} \int\limits_V \exp[-2\pi{\rm i}\sum_{l=1}^{N_v} \mathbb{I}_{\Delta_{l}}(\vb{r}) t_l] {\rm d} \vb{r} \right\}^N.
	\end{eqnarray}
	Applying the following transformation for the integral over $V$
	\begin{equation}
		\int\limits_V \ldots {\rm d} \vb{r} = \sum_{l=1}^{N_v}\int\limits_{\Delta_l} \ldots {\rm d} \vb{r},
	\end{equation}
	and taking into account the definition of $\mathbb{I}_{\Delta_l}$~\eqref{def:I}, one gets for $R_{N_v}$
	\begin{eqnarray}
		\label{eq:RNL}
		R_{N_v}(t_1, \ldots, t_{N_v}) & = & \sum_{N=0}^{\infty}\frac{1}{N!} \left[ \frac{1}{\Lambda^3} \sum_{l=1}^{N_v} \int\limits_{\Delta_l} \exp(-2\pi{\rm i}t_l) {\rm d} \vb{r} \right]^N
		\nonumber\\
		&=& \exp[\frac{v}{\Lambda^3} \sum_{l=1}^{N_v} \exp(-2\pi{\rm i} t_l)].
	\end{eqnarray}
	Here we used an obvious result $\int_{\Delta_l} {\rm d} \vb{r} = v$. It is natural to introduce dimensionless variable
	\begin{equation}
		\label{def:v_star}
		v^* = \frac{v}{\Lambda^3_J},
	\end{equation}
	where we define
	\begin{equation}
		\Lambda_J = (2\pi\hbar^2/mJ_1)^{1/2},
	\end{equation}
	and, thus, write down the final expression for $R_{N_v}$
	\begin{equation}
		\label{eq:RNv}
		R_{N_v}(t_1, \ldots, t_{N_v}) = \exp[v^* T^{*3/2} \sum_{l=1}^{N_v} \exp(-2\pi{\rm i} t_l)].
	\end{equation}
	Compare this expression with the corresponding one in~\cite[p.~4]{KKD20} 
	
	Let us substitute~\eqref{eq:RNv} into~\eqref{eq:XiR}
	\begin{equation}
		\label{eq:XiIntt}
		\Xi(T^*,\mu^*) = \sum_{\varrho \in \mathbb{N}_0^{N_v}} F_{N_v}(T^*, \mu^*; \varrho) \prod\limits_{l=1}^{N_v} \int\limits_{0}^{1} \exp[2\pi{\rm i}\varrho_l t_l + v^* T^{*3/2} \exp(-2\pi{\rm i} t_l)] {\rm d} t_l.
	\end{equation}
	Here, the integral gives the following result (see Appendix~\ref{subsec:int} for details):
	\begin{equation}
		\label{integral1}
		\int\limits_{0}^{1} \exp[2\pi{\rm i}\varrho_l t_l + v^* T^{*3/2} \exp(-2\pi{\rm i} t_l)] {\rm d} t_l = \frac{{(v^* T^{*3/2})}^{\varrho_l}}{\varrho_l !}.
	\end{equation}
	
	The GPF takes on the form (cf.~\cite[2.11]{KKD20}):
	\begin{eqnarray}
		\label{eq:XiPi}
		\Xi(T^*,\mu^*) & = & \sum_{\varrho \in \mathbb{N}_0^{N_v}} F_{N_v}(T^*, \mu^*; \varrho) \prod\limits_{l=1}^{N_v} \frac{(v^* T^{*3/2})^{\varrho_l}}{\varrho_l !}
		\nonumber\\
		& = & \sum_{\varrho \in \mathbb{N}_0^{N_v}} \exp[\frac{1}{2 T^* N_v} \left(\sum_{l=1}^{N_v} \varrho_l\right)^2] \prod\limits_{l=1}^{N_v} \pi(T^*,\mu^*; \varrho_l),
	\end{eqnarray}
	where
	\begin{equation}
		\label{def:pirho}
		\pi(T^*, \mu^*; \varrho_l) = \frac{(v^* T^{*3/2})^{\varrho_l}}{\varrho_l !} \exp(\frac{\mu^*}{T^*}\varrho_l - \frac{a}{2T^*}\varrho_l^2), \quad \varrho_l \in \mathbb{N}_0.
	\end{equation}
	\begin{mdframed}[linecolor=black,linewidth=1pt,leftline=true]
		In a generic form
		\begin{equation}
			\label{def:pin}
			\pi(T^*, \mu^*; n) = \frac{\left(v^* T^{*3/2}\right)^n}{n!} \exp(\frac{\mu^*}{T^*} n - \frac{a}{2T^*}n^2), \quad n \in \mathbb{N}_0.
		\end{equation}
	\end{mdframed}
	
	\textbf{The Poisson distribution} results from~\eqref{def:pin} at $a=0$. To see this, rewrite expression for $\pi(T^*,\mu^*;n)|_{a=0}$ as
	\begin{eqnarray}
		\pi(T^*,\mu^*;n)|_{a=0} & = & \exp({v^* T^{*3/2} {\rm e}^{\beta\mu}}) \cdot
		\frac{\left(v^* T^{*3/2} {\rm e}^{\beta\mu}\right)^n}{n!} \exp({-v^* T^{*3/2} {\rm e}^{\beta\mu}}) 
		\nonumber\\
		& = & \exp({v^* T^{*3/2} {\rm e}^{\beta\mu}}) f(n; \lambda)
	\end{eqnarray}
	where the (non-normalized) Poisson distribution $f(n; \lambda)$ is given by
	\begin{equation}
		f(n; \lambda) = \frac{\lambda^n {\rm e}^{-\lambda}}{n!}, \quad \lambda = v^* T^{*3/2} {\rm e}^{\beta\mu}.
	\end{equation}
	However, the case of $a=0$ corresponds either to the absence of repulsion, $J_2=0$, or to the infinite attraction, $J_1 \to \infty$, and both cases are un-physical for the considered model.
	
	\textbf{Further transformation}. Explicitly applying the Gaussian integral (with parameters $\alpha > 0$, and $\beta \in \mathbb{R}$)
	\begin{equation}
		\int\limits_{-\infty}^{\infty} {\rm e}^{-\alpha y^2 + \beta y} {\rm d}y = \sqrt{\frac{\pi}{\alpha}} {\rm e}^{\frac{\beta^2}{4\alpha}},
	\end{equation}
	to Eq.~\eqref{eq:XiPi}
	\begin{equation}
		\label{eq:gaussInt}
		\exp[\frac{1}{2 T^* N_v}\left(\sum_{l=1}^{N_v} \varrho_l\right)^2] = \sqrt{\frac{N_v T^*}{2\pi}}
		\int\limits_{-\infty}^{\infty} \exp(-\frac{N_v}{2} T^* y^2 + y\sum_{l=1}^{N_v} \varrho_l) {\rm d}y,
	\end{equation}
	we transform~\eqref{eq:XiPi} into the following expression
	\begin{equation}
		\label{eq:XiInty}
		\Xi (T^*, \mu^*) = \sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty} \exp[N_v E(T^*, \mu^*; y)] {\rm d} y,
	\end{equation}
	where 
	\begin{equation}
		\label{def:E}
		E(T^*,\mu^*; y) = -\frac12T^*y^2 + \ln K_0(T^*,\mu^*; y),
	\end{equation}
	with
	\begin{equation}
		\label{def:K}
		K_0(T^*,\mu^*; y) = \sum_{n=0}^{\infty} \frac{\left(v^* T^{*3/2}\right)^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2].
	\end{equation}
	Explicit derivation of expressions for $E(T^*,\mu^*;y)$ and $K_0(T^*,\mu^*;y)$ is given in Appendix~\ref{sec:app1}. The special function $K_0$ is studied from a more generic, mathematical perspective in~\cite{DS25arxiv}.
	
	\textbf{Some reasoning on numerical value of $v^*$.} During particular calculations, a numerical value for $v^*$ must be chosen. Which value to select should depend on physical reasoning. The dependence of results on $v^*$ may also be investigated.
	
	Since $v^* = c^3/\Lambda_J^3$, we may focus on a choice for $c$. One approach to choosing $c$ is in such a way that a classical consideration is justified. For example, it can be taken as the mean nearest-neighbour separation, see~\cite[Sec.~1.1]{HansenMcDonald13}. From the data given in~\cite[Table~1.1]{HansenMcDonald13} for the triple-point temperature, the ratio $c/\Lambda$ may vary between $3.8$ and $59$ (we ignored data for $H_2$, as quantum effects are important for this substance). This defines a possible interval of values for $c^3/\Lambda^3$ as
	\begin{equation}
		\label{vrange}
		57 \leq c^3/\Lambda^3 \leq 2 \cdot 10^5.
	\end{equation}
	In the definition of $v^*$ instead of $\Lambda$ we use $\Lambda_J$, where $k_{\rm B} T$ in the formula for the de Broglie wavelength is substituted by the constant $J_1$. Based on the critical temperature found in previous works~\cite{KKD18, KKD20, KD22}, $k_{\rm B}T_c \approx J_1/4$, the value of $\Lambda_J$ becomes less than the corresponding value of $\Lambda$ at the critical point, and even more so than that at the triple point. Therefore, the ratios of $c^3/\Lambda_J^3$ will be even grater than estimated in~\eqref{vrange}. 
	
	\textbf{Constraint on $E(T^*,\mu^*;y)$}. From inequality
	\begin{equation}
		\left(\frac{T^* y + \mu^*}{a} - n \right)^2 \geq 0,
	\end{equation}
	it follows
	\begin{equation}
		\left(y + \frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2 \leq \left(y + \frac{\mu^*}{T^*}\right)^2 \frac{T^*}{2a}
	\end{equation}
	The last inequality, in turn, leads to corresponding inequalities for $K(T^*,\mu^*;y)$
	\begin{eqnarray}
		K_0(T^*,\mu^*;y) & \leq & \sum_{n=0}^{\infty}\frac{(v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)^2 \frac{T^*}{2a}]
	\end{eqnarray}
	or more concisely
	\begin{equation}
		K_0(T^*,\mu^*;y) \leq \exp[\left(y+\frac{\mu^*}{T^*}\right)^2 \frac{T^*}{2a}] \exp(v^* T^{*3/2}).
	\end{equation}
	For the quantity $E(T^*,\mu^*;y)$ we have
	\begin{equation}
		\label{ineq:E0}
		E(T^*,\mu^*;y) \leq -\frac{a-1}{2a} T^* y^2 + \frac{\mu^*}{2a}\left(2y + \frac{\mu^*}{T^*}\right) + v^* T^{*3/2}.
	\end{equation}
	Since $a>1$, Eq.~\eqref{ineq:E0} implies the following limits for fixed $T^*$ and $\mu^*$
	\begin{equation}
		\lim_{y \to -\infty} E(T^*,\mu^*;y) = -\infty, \quad \lim\limits_{y \to +\infty} E(T^*,\mu^*;y) = -\infty.
	\end{equation}
	A typical behavior of $E(T^*,\mu^*;y)$ as a function of $y$ is illustrated in Fig.~\ref{fig:E0y_vs_y_a} and other Figures in Subsection~\ref{sec:figE0}.
	
	\textit{Remark}. The estimate in~\eqref{ineq:E0} implies the following: (a) the integral in~\eqref{eq:XiInty} converges for all $T^*>0$ and $\mu^* \in \mathbb{R}$, as $a>1$; (b) for fixed $T$ and $\mu$, since $E(T^*,\mu^*;y)$ is bounded above, it has global maxima, each of which is also a local maximum.
	
	\textbf{Note on numerical values for parameters.} If not specified otherwise, the following numerical values for parameters of the model are used for calculations and graphical representation of results:
	\begin{equation}
		v^* = 5.0; \quad a = 1.2.
	\end{equation}
	
	
	\section{Pressure}
	\label{sec:pres}
	By the known thermodynamic formula (cf.~\cite[(2.16)]{KKD20})
	\begin{equation}
		\label{def:eos}
		P V = k_{\rm B} T \ln \Xi
		%P V = \beta^{-1} \ln \Xi
	\end{equation}
	where $P$ is the pressure. To calculate the large $N_v$ limit in~\eqref{eq:XiInty} we first determine the global maxima of $E(T^*,\mu^*;y)$ as a function of $y \in \mathbb{R}$, and then apply the Laplace's method~\cite{Fedoryuk89,BenderOrszag99}.
	
	Let $\bar{y}$ denote the point of extremum of $E(T^*,\mu^*;y)$ with respect to $y$ at given temperature and chemical potential. Then it should obey the following equation
	\begin{equation}
		\label{cond:extr}
		E_1(T^*,\mu^*;\bar{y}) = 0.
	\end{equation}
	where we introduced the quantity
	\begin{equation}
		\label{def:E1}
		E_1(T^*,\mu^*;y) := \frac{\partial}{\partial y} E(T^*,\mu^*;y).
	\end{equation}
	By~\eqref{def:E} and~\eqref{def:K}, the explicit expression for $E_1$ is given by
	\begin{equation}
		\label{def:reducedE1}
		E_1(T^*,\mu^*;y) = -T^* y + \frac{K_1(T^*,\mu^*;y)}{K_0(T^*,\mu^*;y)}.
	\end{equation}
	Thus the equation for $\bar{y}$, resulting from the condition of extremum for $E(T^*,\mu^*;y)$, takes on the form~(cf.~\cite[(2.19)]{KKD20})
	\begin{equation}
		\label{eq:bar_y}
		-T^* \bar{y} + \frac{K_1(T^*,\mu^*;\bar{y})}{K_0(T^*,\mu^*;\bar{y})} = 0,
	\end{equation}
	which is an implicit equation defining $\bar{y} = \bar{y}(T^*,\mu^*)$ as a function of $T^*$ and $\mu^*$.
	The function $K_1$ is given by
	\begin{eqnarray}
		K_1(T^*,\mu^*;y) & := & \frac{\partial}{\partial y} K_0(T^*,\mu^*;y)
		\nonumber\\
		& = & \sum_{n=0}^{\infty} \frac{n (v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2].
	\end{eqnarray}
	
	As $K_0$, $K_1$, and $T^*$ all take on strictly positive values, the solution $\bar{y}$ to equation~\eqref{eq:bar_y} is also strictly positive, i.e. $\bar{y} \in \mathbb{R}^{+}$.
	Figure~\ref{fig:YvsMu_a1} illustrates dependence of $\bar{y}$ on $\mu^*$ at some values of temperature $T^*$. We can see that at high temperature value, $T^*=0.4$, $\bar{y}$ is a one-valued function of $\mu^*$. At low temperature, $T^*=0.2$, there are some intervals in $\mu^*$ where $\bar{y}$ is a multi-valued function of $\mu^*$. The intermediate range of temperatures, where $\bar{y}$ changes its nature from a singe-valued to a multi-valued function of $\mu^*$ is of particular interest and will be investigated more closely in Section~\ref{sec:CP}. Figure~\ref{fig:YvsT_a2} illustrates dependence of $\bar{y}$ on $T^*$ for a few values of $\mu^*$. We can see that in the presented temperature range, $\bar{y}$ increases with $T^*$ for small values of $\mu^*$ and decreases for $\mu^*=0.5$. It is also interesting to study how the crossover from one type of behavior to another occurs in the region of intermediate values for $\mu^*$.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{images/YvsMu_a1}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{images/YvsT_a2}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:YvsMu_a1} Solution $\bar{y}$ to the equation $E_1(T^*,\mu^*;\bar{y})=0$ as a function of $\mu^*$ for a few values of $T^*$. Dash line (black): $T^* = 0.4$; Dash-dotted line (red): $T^* = 0.25$; Solid line: $T^*=0.2$.}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:YvsT_a2} Solution $\bar{y}$ to the equation $E_1(T^*,\mu^*;\bar{y})=0$ as a function of $T^*$ for a few values of $\mu^*$. Dash line (red): $\mu^* = -1.0$, Dash-dotted line (blue): $\mu^* = 0.0$, Solid line (black): $\mu^* = 0.5$.}}
	\end{figure}
	
	\textbf{Definition}. We say that $(T^*, \mu^*)$ belongs to a single-phase domain if $E(T^*,\mu^*;y)$ has a unique global maximum $\bar{y}_{\rm max} \in \mathbb{R}^{+}$ such that~\footnote{It is important to distinguish between $\bar{y}$ and $\bar{y}_{\rm max}$, as $\bar{y}$ can be either a maximum or a minimum of $E$ depending on the specific values of $T^*$ and $\mu^*$, whereas $\bar{y}_{\rm max}$ is strictly a maximum.}
	\begin{eqnarray}
		\label{cond:max}
		E_1(T^*, \mu^*; \bar{y}_{\rm max}) & = & 0,
		\nonumber\\
		E_2(T^*, \mu^*;\bar{y}_{\rm max}) & < & 0,
	\end{eqnarray}
	where we introduced the quantity
	\begin{eqnarray}
		\label{def:E2}
		E_2(T^*, \mu^*;y) & := & \frac{\partial^2}{\partial y^2} E(T^*,\mu^*;y)
		\\
		& = & \frac{\partial}{\partial y} E_1(T^*,\mu^*;y).
		\nonumber
	\end{eqnarray}
	The explicit expression for $E_2(T^*,\mu^*;y)$ reads (cf.~\cite[(20)]{KD22})
	\begin{equation}
		\label{def:reducedE2}
		E_2(T^*,\mu^*;y) = -T^* + \frac{K_2(T^*,\mu^*;y) K_0(T^*,\mu^*;y) - [K_1(T^*,\mu^*;y)]^2}{[K_0(T^*,\mu^*;y)]^2},
	\end{equation}
	where
	\begin{eqnarray}
		K_2(T^*,\mu^*;y) & := & \frac{\partial}{\partial y} K_1(T^*,\mu^*;y)
		\nonumber\\
		& = & \sum_{n=0}^{\infty} \frac{n^2 (v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2].
	\end{eqnarray}
	
	Typical behavior of $E_1(T^*,\mu^*;y)$ as a function of $y$ is illustrated in Fig.~\ref{fig:E1y_vs_y_a} and other Figures in Subsection~\ref{sec:figE1}.	
	Typical behavior of $E_2(T^*,\mu^*;y)$ as a function of $y$ is illustrated in~Fig.~\ref{fig:E2y_vs_y_a} and other Figures in Subsection~\ref{sec:figE2}.
	
	\textbf{Laplace's method.} We apply the Laplace's method~(\cite[(1.21)]{Fedoryuk89}, \cite[(6.4.19c)]{BenderOrszag99}) to~\eqref{eq:XiInty} and arrive at~(cf.~\cite[(19)]{KD22})
	\begin{equation}
		\label{laplace1}
		\Xi(T^*,\mu^*) = \left[-\frac{T^*}{E_2(T^*,\mu^*;\bar{y}_{\rm max})}\right]^{1/2} \exp[N_v E(T^*,\mu^*;\bar{y}_{\rm max})].
	\end{equation}
	Substituting this into~\eqref{def:eos}, one obtains
	\begin{equation}
		P V = k_{\rm B}T \left[-\frac{1}{2} \ln(-\frac{E_2(T^*,\mu^*;\bar{y}_{\rm max})}{T^*}) + N_v E(T^*,\mu^*;\bar{y}_{\rm max})\right].
	\end{equation}
	The first term in the square brackets in the right-hand side of the last equation can be neglected in the limit of large $N_v$, and we arrive at (cf.~\cite[(2.27)]{KKD20})
	\begin{equation}
		\frac{P V}{k_{\rm B}T N_v} = E(T^*,\mu^*;\bar{y}_{\rm max}),
	\end{equation}
	or
	\begin{equation}
		\label{eos:reduced}
		P^*(T^*,\mu^*) = T^* E(T^*,\mu^*;\bar{y}_{\rm max}).
	\end{equation}
	We have obtained an expression for the pressure $P^*$ as a function of temperature $T^*$ and chemical potential $\mu^*$, $P = P(T^*, \mu^*)$. We also remember that the quantity $\bar{y}_{\rm max}$, which is selected from the condition to maximize $E$ at given $T^*$ and $\mu^*$, is a function of $T^*$ and $\mu^*$ itself, $\bar{y}_{\rm max} = \bar{y}_{\rm max}(T^*,\mu^*)$. Since we can't obtain an analytic solution to~\eqref{eq:bar_y}, we will use numerical methods to approximate $\bar{y}$ and then illustrate the results graphically.

	
	\pagebreak
	\section{Application of the implicit function theorem to the extremum condition}
	The equation~\eqref{eq:bar_y} implicitly defines $\bar{y}$ as a function of temperature and chemical potential. We can benefit from the implicit function theorem to get some results for $\bar{y}$ and its derivatives with respect to chemical potential and temperature.
	
	First, let us recall that if a line is given by 
	\begin{equation*}
		{\cal F}(x,y) = 0,
	\end{equation*}
	and if ${\cal F}(x,y)$ is continuously differentiable on some open domain around $(x_0,y_0)$, then
	\begin{equation}
		\frac{{\rm d} y}{{\rm d} x} = - \frac{\partial {\cal F} / \partial x}{\partial {\cal F} / \partial y}.
	\end{equation}
	Applying this to~\eqref{cond:extr} -- \eqref{eq:bar_y}, we get
	\begin{equation}
		\left(\frac{\partial \bar{y}}{\partial \mu^*}  \right)_{T^*} = - \frac{\partial E_1 / \partial \mu^*}{\partial E_1 / \partial \bar{y}}.
	\end{equation}
%	\begin{equation}
%		\left(\frac{\partial \bar{y}}{\partial \mu^*}  \right)_{T^*} = - \frac{\partial E_1(T^*,\mu^*;y) / \partial \mu^*}{\partial E_1(T^*,\mu^*;y) / \partial y}\bigg|_{y=\bar{y}}.
%	\end{equation}
	Here we understand $\partial E_1 / \partial \bar{y} = \partial E_1(T^*,\mu^*;y) / \partial y |_{T^*,\mu^*,y=\bar{y}}$, and $\partial E_1 / \partial\mu^* = \partial E_1(T^*,\mu^*;y) / \partial \mu^* |_{T^*,y=\bar{y}}$.
	By definition~\eqref{def:E2}
	\begin{equation}
		\frac{\partial E_1}{\partial \bar{y}} = E_2(T^*,\mu^*;\bar{y}).
	\end{equation}
	For $\partial E_1 / \partial \mu^*$ one has
	\begin{equation}
		\label{dE1dmu1}
		\frac{\partial E_1}{\partial \mu^*} = \frac{1}{T^*} [E_2(T^*,\mu^*;\bar{y}) + T^*].
	\end{equation}
	The quantity $E_2(T^*,\mu^*;\bar{y})$ can be rewritten as (cf.~\cite[(2.23)]{KKD20})
	\begin{eqnarray}
		\label{E2a}
		E_2(T^*,\mu^*;\bar{y}) & = & -T^* + \frac{1}{2 [K_0(T^*,\mu^*;\bar{y})]^2}
		\\
		& \times & \sum_{n_1, n_2 = 0}^{\infty} \frac{(v^* T^{*3/2})^{n_1+n_2}}{n_1!n_2!}(n_1 - n_2)^2 \exp[\left(\bar{y} + \frac{\mu^*}{T^*}\right)(n_1 + n_2) - \frac{a}{2T^*}(n_1^2 + n_2^2)],\nonumber
	\end{eqnarray}
	leading to
	\begin{equation}
		\label{E2pT}
		E_2(T^*,\mu^*;\bar{y}) + T^* > 0,
	\end{equation}
	and thus
	\begin{equation}
		\label{dE1dmu2}
		\frac{\partial E_1}{\partial \mu^*} > 0.
	\end{equation}
	Substituting the results back into $\partial \bar{y}/\partial \mu^*$, one gets
	\begin{equation}
		\label{dydm}
		\left(\frac{\partial \bar{y}}{\partial \mu^*} \right)_{T^*} = -\frac{E_2(T^*,\mu^*;\bar{y}) + T^*}{T^* E_2(T^*,\mu^*;\bar{y})}.
	\end{equation}
	We can also consider $\mu^*$ as a function of $\bar{y}$ and $T^*$, and get
	\begin{equation}
		\left(\frac{\partial \mu^*}{\partial \bar{y}} \right)_{T^*} = -\frac{T^* E_2}{E_2 + T^*}.
	\end{equation}
	Since the condition of maximum~\eqref{cond:max} implies $E_2 < 0$, it follows that
	\begin{equation}
		\left(\frac{\partial \bar{y}_{\rm max}}{\partial \mu^*} \right)_{T^*} > 0.
	\end{equation}
	
	Note that relations~\eqref{dE1dmu1}, \eqref{E2a}, \eqref{E2pT}, and~\eqref{dE1dmu2} are valid for an arbitrary $y$, i.e. we may replace $\bar{y}$ with either $y$ or $\bar{y}_{\rm max}$ there and they will still be valid.
	
	
	\pagebreak
	\section{Average number of particles}
	By thermodynamic formulas for the grand canonical ensemble
	\begin{eqnarray}
		\langle N \rangle & = & -\left(\frac{\partial \Omega}{\partial \mu}\right)_{T,V}
		\nonumber\\
		& = & V \left(\frac{\partial P}{\partial \mu}\right)_T,
	\end{eqnarray}
	where $\Omega$ is the grand potential
	\begin{equation}
		\Omega = -k_{\rm B} T \ln \Xi.
	\end{equation}
	For the reduced density it follows
	\begin{equation}
		\label{eq:dens}
		\rho^* = v\left(\frac{\partial P}{\partial \mu}\right)_T = \left(\frac{\partial P^*}{\partial \mu^*}\right)_{T^*}.
	\end{equation}
	As a result of the differentiation of pressure with respect to chemical potential (see Appendix~\ref{sec:app:dens} for details), one gets
	\begin{eqnarray}
		\label{eq:densK}
		\rho^*(T^*,\mu^*) & = & \frac{K_1(T^*,\mu^*;\bar{y}_{\rm max})}{K_0(T^*,\mu^*;\bar{y}_{\rm max})}.
	\end{eqnarray}
	
	The quantity $\rho^*$, on the one hand, is the reduced particle number density, which is the notation commonly used in the literature on simple liquids~\cite{HansenMcDonald13}. In the context of the cell model, on the other hand, it also has the meaning of the average number of particles per cell, since
	\begin{equation}
		\rho^* = \frac{\langle N \rangle}{V} v = \frac{\langle N \rangle}{N_v}.
	\end{equation}
	
	From~\eqref{eq:bar_y} it also follows that
	\begin{equation}
		\label{rho_vs_T_mu}
		\rho^*(T^*,\mu^*) = T^* \bar{y}_{\rm max}(T^*,\mu^*).
	\end{equation}
	%This enables us to calculate the equation of state.
	
	
	\section{Equation of state}
	We have got relation $P^* = P^*(T^*, \mu^*)$ in~\eqref{eos:reduced}. Now, having found the density $\rho^* = \rho^*(T^*,\mu^*)$ in~\eqref{rho_vs_T_mu}, we can formally solve this equation with respect to $\mu^*$ to find $\mu^* = \mu^*(T^*,\rho^*)$, and substitute back into~\eqref{eos:reduced} to get pressure as a function of density and temperature (cf.~\cite[(2.28)]{KKD20})
	\begin{equation}
		\label{eos}
		P^*(T^*,\rho^*) = T^* E\left[T^*, \mu^*(T^*,\rho^*); \frac{\rho^*}{T^*}\right],
	\end{equation}
	which will be the equation of state in convenient (wide-spread, generally accepted) terms. However, such task is not an easy one, and at the moment we can solve~\eqref{rho_vs_T_mu} with respect to $\mu^*$ only numerically. Nevertheless, even formal consideration of equation~\eqref{eos} is helpful to determine the critical points coordinates, see the next Section~\ref{sec:CP}.
	
	\pagebreak
	\section{\label{sec:CP} Critical point coordinates}
	
	In this section we investigate the region of temperature and chemical potential where the solution $\bar{y}$ to Eq.~\eqref{eq:bar_y} becomes a multi-valued function of $\mu^*$. The point where such an event occurs is called a critical point. The existence of such a point can already be seen from the behavior of quantity $E(T^*,\mu^*;y)$ as a function of $y$. Figure~\ref{fig:EvsYvs_barY_a1} shows several curves for $E$ versus $y$ at $T^*=0.4$ and different values of chemical potential. For any curve, the coordinate of a maximum corresponds to $\bar{y}$ at particular $(T^*,\mu^*)$. We conclude that at this temperature, $\bar{y}(T^*,\mu^*)$ always maximizes $E$. The solid thick line, passing all the maxima, represents the dependence of $E$ versus $\bar{y}$, and at the same time, that of $E$ versus $\bar{y}_{\rm max}$.
	
	Figure~\ref{fig:EvsYvs_barY_b1} shows several curves for $E$ versus $y$ at $T^*=0.2$ and different values of chemical potential. For a small value of chemical potential, $\mu^*=0.2$, one maximum is observed at a small $y$. With increasing $\mu^*$, a second maximum is developed at a larger $y$, and a minimum between the two maxima. As $\mu^*$ continues to increase, the second maximum first becomes equal to the first one and eventually exceeds it. With farther increase of $\mu^*$, the first maximum disappears (ceases to exist), and the second maximum becomes the only one to exist. If we continue to increase $\mu^*$, see Fig.~\ref{fig:EvsYvs_barY_b3}, the third maximum appears, that eventually exceeds the second one and becomes the main one. It seems that for the considered model such process can be continued infinitely, and each time a new maximum will appear for larger and larger $y$. Figure~\ref{fig:EvsYvs_barY_b4} illustrates this idea by combining results of Figs.~\ref{fig:EvsYvs_barY_b1} and~\ref{fig:EvsYvs_barY_b3}, and extending to higher values of $y$. 
	
	At low temperatures, there are intervals in $y$ where $E$ possesses both maxima and minima. To obey the requirements for the Laplace's method, we should eliminate those solutions $\bar{y}$ that give a minimum for $E$, and keep only those that give maxima. We denote such solutions $\bar{y}_{\rm max}$, see Eq.~\eqref{cond:max}. Additionally, in the case when $E$ possesses two maxima with respect to $y$, we must chose only the higher one, and exclude the lower one. The highest maximum is called {\it the global maximum}. Solutions $\bar{y}_{\rm max}$ that lead to the global maximum are called {\it stable}. Those $\bar{y}_{\rm max}$ that do not lead to the global maximum are called {\it metastable}. Those $\bar{y}$ that lead to a minimum of $E$ are called {\it unstable}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.42\textwidth,angle=0]{images/EvsYvs_barY_a3}
		\hfill
		\includegraphics[width=0.42\textwidth,angle=0]{images/EvsYvs_barY_b2_1}
		%\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.45\textwidth}{\caption{\label{fig:EvsYvs_barY_a1} Thin solid lines represent $E(T^*,\mu^*;y)$ as a function of $y$ at $T^*=0.4$ and the following values of $\mu^*$ (from bottom up): -0.1, 0.1, 0.3, 0.5, and 0.7. Thick solid line represents $E(T^*,\mu^*;\bar{y})$ versus $\bar{y}$ at the same temperature $T^* = 0.4$.}}
		\hfill
		\parbox{0.45\textwidth}{\caption{\label{fig:EvsYvs_barY_b1} Thin solid lines represent $E(T^*,\mu^*;y)$ as a function of $y$ at $T^*=0.2$ and the following values of $\mu^*$ (from bottom up): 0.2, 0.23, 0.25, 0.26, and 0.28. Thick solid line represents $E(T^*,\mu^*;\bar{y}_{\rm max})$ versus $\bar{y}_{\rm max}$ at the same temperature $T^* = 0.2$.}}
		%\captionsetup{width=0.45\textwidth}
		
	\end{figure}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.42\textwidth,angle=0]{images/EvsYvs_barY_b3}
		\hfill
		\includegraphics[width=0.42\textwidth,angle=0]{images/EvsYvs_barY_b4}
		%\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.45\textwidth}{\caption{\label{fig:EvsYvs_barY_b3} Thin solid lines represent $E(T^*,\mu^*;y)$ as a function of $y$ at $T^*=0.2$ and the following values of $\mu^*$ (from bottom up): 0.30, 0.50, 0.55, 0.60, and 0.65. Thick solid line represents $E(T^*,\mu^*;\bar{y}_{\rm max})$ versus $\bar{y}_{\rm max}$ at the same temperature $T^* = 0.2$.}}
		\hfill
		\parbox{0.45\textwidth}{\caption{\label{fig:EvsYvs_barY_b4} Thick solid lines represents $E(T^*,\mu^*;\bar{y}_{\rm max})$ versus $\bar{y}_{\rm max}$ at temperature $T^* = 0.2$. Thin solid lines represent $E(T^*,\mu^*;y)$ as a function of $y$ at $T^*=0.2$ and at some arbitrary values of $\mu^*$ ranging from 0.2 (the lowest line) to 0.95 (the topmost line).}}
		%\captionsetup{width=0.45\textwidth}
		
	\end{figure}
	
	The above analysis suggests that in the considered model there exist multiple first-order phase transitions at sufficiently low temperatures, and there are no phase transitions at sufficiently high temperatures. The question arises whether those first-order phase transitions end with corresponding critical points? The most natural way to investigate this question in many-body interacting systems is in terms of pressure and density. We will proceed with such an investigation.
	
	From the general theories of phase transitions and critical phenomena, we have got a recipe to find the coordinates of a critical point from an equation of state in the form $P=P(T,\rho)$. Since the critical point is the inflection point on the critical isotherm, we have two conditions
	\begin{equation}
		\begin{split}
			\left(\frac{\partial P^*}{\partial \rho^*}\right)_{T^*} = 0;
			\\
			\left(\frac{\partial^2 P^*}{\partial \rho^{*2}}\right)_{T^*} = 0.
		\end{split}		
	\end{equation}
	As is shown in Appendix~\ref{sec:app:cp}, these two conditions are equivalent to
	\begin{equation}
		\label{E2E3eq0}
		\begin{split}
			E_2 = 0,
			\\
			E_3 = 0,
		\end{split}
	\end{equation}
	where we introduced the quantity
	\begin{equation}
		\begin{split}
			E_3(T^*,\mu^*;\bar{y}) &:= \frac{\partial^3}{\partial y^3} E(T^*,\mu^*; y)\big|_{y=\bar{y}} 
			\\
			& = \frac{\partial}{\partial \bar{y}} E_2(T^*,\mu^*; \bar{y}).
		\end{split}
	\end{equation}
	The explicit expression for $E_3$ reads
	\begin{equation}
		E_3(T^*,\mu^*;\bar{y}) = \frac{K_3(T^*;\mu^*;\bar{y})}{K_0(T^*;\mu^*;\bar{y})} - \frac{3 K_2(T^*;\mu^*;\bar{y}) K_1(T^*;\mu^*;\bar{y})}{K_0(T^*;\mu^*;\bar{y})^2} + \frac{2K_1(T^*;\mu^*;\bar{y})^3}{K_0(T^*;\mu^*;\bar{y})^3}.
	\end{equation}
	Together with Eq.~\eqref{eq:bar_y} we have three equations with three unknown values for $T^*$, $\mu^*$, and $\bar{y}$:
	\begin{equation}
		\label{eq:system}
		\begin{cases}
			E_1(T^*,\mu^*; \bar{y}) = 0,\\
			E_2(T^*,\mu^*; \bar{y}) = 0,\\
			E_3(T^*,\mu^*; \bar{y}) = 0.
		\end{cases}
	\end{equation}
	We can resolve this system of equations numerically, and find the critical point coordinates $T^*_c$, $\mu^*_c$, and $\bar{y}_c$.
	
	The cell model with Curie-Weiss interaction is known to possess multiple critical points~\cite{KKD18,KKD20,KD22}. Thus the system of equations~\eqref{eq:system} has many sets of solutions. We denote such solutions by natural numbers $n$, starting with $n=1$ for the lowest critical temperature. Table~\ref{tab:cp} contains the found sets of solutions, as well as the values for other physical quantities at the critical points calculated based on $T^*_c$, $\mu^*_c$, and $\bar{y}_c$.
	
	\textbf{Note on application of the Laplace's method} at the critical point. Since $E_2 = 0$, the formula~\eqref{laplace1} is not applicable anymore. But if the quantity $E_4 < 0$ at the critical point, then we may apply the following formula (based on~\cite[6.4.19d]{BenderOrszag99})
	\begin{equation}
		\Xi = \sqrt{\frac{N_v T^*}{2\pi}} \frac{2\Gamma(1/4) (4!)^{1/4}}{4[-N_v E_4(T^*_c,\mu^*_c)]^{1/4}} \exp[N_v E(T^*_c,\mu^*_c; \bar{y}_c)].
	\end{equation}
	which in the limit of $N_v \to \infty$ does not change the expressions for pressure~\eqref{eos:reduced}.
	
	\begin{table}[h]
		\centering
		\caption{The critical point values for some quantities. The number $n$ denotes the critical points starting with $n=1$ for the one with the lowest temperature.}
		\begin{tabular}{c|c|c|c|c|c|c|}
			\hline
			$n$ & $T^*_c$ & $\mu^*_c$ & $\bar{y}_c$ & $\beta^*_c$ & $\rho^*_c$ & $P^*_c$ \\
			\hline
			1 & 0.254567 & 0.209380 & 2.01870 & 3.92823 & 0.513896 & 0.0503397  \\
			2 & 0.261881 & 0.585097 & 5.74906 & 3.81852 & 1.50557 & 0.437695  \\
			3 & 0.265254 & 0.891843 & 9.43632 & 3.76996 & 2.50303 & 1.05817 \\
			4 & 0.267242 & 1.16893  & 13.1039 & 3.74193 & 3.50191 & 1.89369 \\
			5 & 0.268562 & 1.42932  & 16.7608 & 3.72354 & 4.50131 & 2.93781 \\
			\hline
			$n$ & $\beta_c\mu_c$ & $\beta_c P_c v$ & $\bar{z}_c=\bar{y}_c+\mu^*_c/T^*_c$ & $\bar{y}_c+\mu^*_c/T^*_c + \ln v^*$ & $\frac{T_c(n)}{T_c(n-1)}$ & $\frac{T_c(n)}{T_c(n=1)}$ \\
			\hline
			1 & 0.822492 & 0.197746 & 2.84119 & 4.45063 & $-$ & 1.00000 \\
			2 & 2.23421  & 1.67135  & 7.98327 & 9.59270 & 1.02873 & 1.02873 \\
			3 & 3.36222  & 3.98927  & 12.7985 & 14.4080 & 1.01288 & 1.04198 \\
			4 & 4.37404  & 7.08603 & 17.4779 & 19.0874 & 1.00749 & 1.04979 \\
			5 & 5.32214  & 10.9390 & 22.0829 & 23.6924 & 1.00494 & 1.05497 \\
			\hline
			$n$ & $E(T^*_c,\mu^*_c)$ & $E_1(T^*_c,\mu^*_c)$ & $E_2(T^*_c,\mu^*_c)$ & $E_3(T^*_c,\mu^*_c)$ & $E_4(T^*_c,\mu^*_c)$ & $S^*_c$  \\
			\hline
			1 & 0.197746 & 0.0 & 0.0 & 0.0 & -0.120306 & 2.43173 \\
			2 & 1.67135  & 0.0 & 0.0 & 0.0 & -0.113509 & 1.34933 \\
			3 & 3.98927  & 0.0 & 0.0 & 0.0 & -0.110425 & 0.914901 \\
			4 & 7.08603  & 0.0 & 0.0 & 0.0 & -0.108631 & 0.631157 \\
			5 & 10.9390  & 0.0 & 0.0 & 0.0 & -0.107455 & 0.417427 \\
			\hline
		\end{tabular}
		\label{tab:cp}
	\end{table}
	
	
	\pagebreak
	\section{Graphical representation of results}
	
	Taking into account results of Section~\ref{sec:CP}, we can now illustrate some result from previous sections graphically. 
	
	The dependence of the number density $\rho^*$ on the chemical potential $\mu^*$ at three representative values of temperature $T^*$ is illustrated in Fig.~\ref{fig:rho_vs_mu_a1}. The corresponding temperature values are (i) $T=0.4$, which is greater than any critical temperature, (ii) $T=0.25$, which is slightly lower than the critical temperature values, and (iii) $T=0.2$, which is much lower than the critical temperatures.
	
	The dependence of the pressure $P^*$ on the chemical potential $\mu^*$ at the same three temperatures is demonstrated in Fig.~\ref{fig:p_vs_mu_a1}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{images/rho_vs_mu_a1}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{images/p_vs_mu_a1}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:rho_vs_mu_a1} The particle number density $\rho^*(T^*,\mu^*)$ as a function of $\mu^*$ at different values of temperature: Red - $T^*=0.4$; Blue - $T^*=0.25$; Green - $T^*=0.20$.}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:p_vs_mu_a1} Pressure $P^*(T^*,\mu^*)$ as a function of $\mu^*$ at different values of temperature: Red - $T^*=0.4$; Blue - $T^*=0.25$; Green - $T^*=0.20$.}}
	\end{figure}
	
	The pressure as a function of density is shown in Fig.~\ref{fig:p_vs_rho_a1}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.5\textwidth,angle=0]{images/p_vs_rho_a1}
		\centering
		\captionsetup{width=0.6\textwidth}
		\caption{Pressure $P^*$ as a function of $\rho^*$ at different values of temperature: Red - $T^*=0.4$; Blue - $T^*=0.25$; Green - $T^*=0.20$.}
		\label{fig:p_vs_rho_a1}
	\end{figure}
	
	
	\pagebreak
	\section{Entropy}
	By thermodynamic formulas for the grand canonical ensemble, we have for the entropy
	\begin{equation}
		S = -\left(\frac{\partial \Omega}{\partial T}\right)_{V,\mu} = V\left(\frac{\partial P}{\partial T}\right)_{\mu}.
	\end{equation} 
	
	At this point, there are two possibilities to normalize entropy. One possibility is to normalize it by the average number of particles
	\begin{equation}
		S^{*} = \frac{S}{k_{\rm B} \langle N \rangle},
	\end{equation}
	and call this quantity the entropy per particle. Another possibility is to normalize it by the number of cells
	\begin{equation}
		S^{**} = \frac{S}{k_{\rm B}N_v},
	\end{equation}
	and call this quantity the entropy per cell. The usage of the entropy per particle, $S^*$, is more common in the theory of many-particle systems~\cite{HansenMcDonald13}, while the entropy per cell, $S^{**}$, may be useful in cell (or lattice) models. For completeness, we will present results for both quantities. We will also call $S^*$ the reduced entropy.
	
	
	The reduced entropy reads
	\begin{eqnarray}
		S^* & = & \frac{v}{k_{\rm B}} \frac{N_v}{\langle N \rangle} \left(\frac{\partial P}{\partial T}\right)_{\mu}
		\\
		& = & \frac{1}{\rho^*}\left(\frac{\partial P^*}{\partial T^*}\right)_{\mu}
		\\
		& = & \frac{(\partial P^* / \partial T^*)_{\mu}}{(\partial P^* / \partial \mu^*)_T}.
	\end{eqnarray}
	By~\eqref{eos:reduced}
	\begin{equation}
		\label{eq:entropy}
		S^*(T^*,\mu^*) = \frac{1}{\rho^*(T^*,\mu^*)} 
		\left[ 
		E(T^*,\mu^*;\bar{y}_{\rm max}) + T^* \left(\frac{\partial E(T^*,\mu^*;\bar{y}_{\rm max})}{\partial T^*}\right)_{\mu^*} 
		\right].
	\end{equation}
	The result of calculation is
	\begin{equation}
		\label{S_vs_T_mu}
		S^*(T^*,\mu^*) = \left(\frac{3}{2} - \frac{\mu^*}{T^*}\right) - \frac{1}{T^*}\frac{K_1}{K_0} + \frac{K_0 \ln K_0}{K_1} + \frac{a}{2T^*} \frac{K_2}{K_1},
	\end{equation}
	where for the special functions we imply $K_i = K_i(T^*,\mu^*;\bar{y}_{\rm max})$.
	The first contribution to the entropy corresponds to the entropy of non-interacting molecules in a lattice, or an ideal lattice gas contribution, see~\cite[(47.4)]{Hill56}, if we account for the ideal-gas chemical potential $\mu_{\rm id} = k_{\rm B}T \ln(N\Lambda^3/V)$. 
	
	
	\textbf{Entropy per cell.} The relation between $S^*$ and $S^{**}$ is
	\begin{equation}
		S^* = \frac{1}{\rho^*} S^{**},
	\end{equation}
	where
	\begin{equation}
		\label{eq:entropy2}
		S^{**}  = \left(\frac{\partial P^*}{\partial T^*}\right)_{\mu^*}.
	\end{equation}
	The expressions for the entropy per cell is
	\begin{eqnarray}
		S^{**}(T^*,\mu^*) & = & \left(\frac{3}{2} - \frac{\mu^*}{T^*}\right)\frac{K_1}{K_0} - \frac{1}{T^*}\frac{K_1^2}{K_0^2} + \ln K_0 + \frac{a}{2T^*} \frac{K_2}{K_0}
	\end{eqnarray}
	Details or calculation are present in Appendix~\ref{sec:app:entropy}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.55\textwidth,angle=0]{S_vs_T1}
		\centering
		%\hfill
		%\includegraphics[width=0.45\textwidth,angle=0]{SS_vs_T2}
		%\\
		\captionsetup{width=0.5\textwidth}
		%\parbox{0.45\textwidth}
		{\caption{\label{fig:S_vs_T1} Entropy $S^{*}(T^*,\mu^*)$ as a function of $T^*$ at $\mu^*=-1.0$ ($v^* = 5$).}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		%\parbox{0.45\textwidth}{\caption{\label{fig:S_vs_T2} Entropy $S^{**}(\bar{y},T^*,\mu^*)$ as a function of $T^*$ at $\mu^*=-1.0$ ($v^* = 5$)}}
	\end{figure}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{SS_vs_T1}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{SS_vs_T2}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:SS_vs_T1} Entropy $S^{**}(T^*,\mu^*)$ as a function of $T^*$ at $\mu^*=-1.0$ ($v^* = 5$).}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:SS_vs_T2} Entropy $S^{**}(T^*,\mu^*)$ as a function of $T^*$ at $\mu^*=-1.0$ ($v^* = 5$).}}
	\end{figure}
	
	\textbf{Graphics for Entropy.} The dependence of the reduced entropy $S^*$ on temperature $T^*$ at a given chemical potential is illustrated in Fig.~\ref{fig:S_vs_T1}. Figures~\ref{fig:SS_vs_T1} and~\ref{fig:SS_vs_T2} illustrate the dependence of entropy per cell $S^{**}$ on temperature $T^*$ at a constant chemical potential. The two figures for $S^{**}$ show the same functional dependence but focus on different temperature ranges.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{S_vs_mu}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{SS_vs_mu}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:S_vs_mu} Entropy per particle $S^{*}(T^*,\mu^*)$ as a function of $\mu^*$ at $T^*=0.5$ ($v^* = 5$).}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:SS_vs_mu} Entropy per cell $S^{**}(T^*,\mu^*)$ as a function of $\mu^*$ at $T^*=0.5$ ($v^* = 5$).}}
	\end{figure}
	
	The dependence of the reduced entropy $S^*$ on chemical potential $\mu^*$ at a given temperature is illustrated in Fig.~\ref{fig:S_vs_mu}. That of $S^{**}$ is shown in Fig.~\ref{fig:SS_vs_mu}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{S_vs_rho}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{SS_vs_rho}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:S_vs_rho} Entropy per particle $S^{*}$ as a function of $\rho^*$, (Dashed black line) at $T^*=0.5$, and (Solid blue line) at $T^*=0.15$.}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:SS_vs_rho} Entropy per cell $S^{**}$ as a function of $\rho^*$, (Dashed black line) at $T^*=0.5$, and (Solid blue line) at $T^*=0.15$.}}
	\end{figure}
	
	The equation for entropy~\eqref{S_vs_T_mu} expresses entropy as a function of temperature and chemical potential. If we want to have entropy as a function of temperature and density, we combine equations~\eqref{S_vs_T_mu} and~\eqref{rho_vs_T_mu} into a parametric equation for entropy, with $\mu^*$ being the parameter. This way we can plot the dependence of entropy on density at a given temperature. Such dependencies are present in Fig.~\ref{fig:S_vs_rho} and~Fig.~\ref{fig:SS_vs_rho}.
	
	
	\pagebreak
	
	\section{Figures}
	\subsection{Figures for $E(T^*,\mu^*;y)$}
	\label{sec:figE0}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_a1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_a2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_a3}
		\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E0y_vs_y_a} Quantity $E(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $T^*=0.5$; Center: $T^*=0.25$; Right: $T^*=0.2$. Lines: Blue: $\mu^*=-1.0$; Green: $\mu^*=0.0$; Red: $\mu^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_b1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_b2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E0y_vs_y_b3}
		%\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E0y_vs_y_b} Quantity $E(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $\mu^*=-1.0$; Center: $\mu^*=0.0$; Right: $\mu^*=0.5$. Lines: Navy: $T^*=0.2$; Aquamarine: $T^*=0.25$; Maroon: $T^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\pagebreak
	
	\subsection{Figures for $E_1(T^*,\mu^*;y)$}
	\label{sec:figE1}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_a1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_a2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_a3}
		\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E1y_vs_y_a} Quantity $E_1(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $T^*=0.5$; Center: $T^*=0.25$; Right: $T^*=0.2$. Lines: Blue: $\mu^*=-1.0$; Green: $\mu^*=0.0$; Red: $\mu^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_b1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_b2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E1y_vs_y_b3}
		%\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E1y_vs_y_b} Quantity $E_1(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $\mu^*=-1.0$; Center: $\mu^*=0.0$; Right: $\mu^*=0.5$. Lines: Navy: $T^*=0.2$; Aquamarine: $T^*=0.25$; Maroon: $T^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\pagebreak
	
	\subsection{Figures for $E_2(T^*,\mu^*;y)$}
	\label{sec:figE2}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_a1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_a2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_a3}
		\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E2y_vs_y_a} Quantity $E_2(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $T^*=0.5$; Center: $T^*=0.25$; Right: $T^*=0.2$. Lines: Blue: $\mu^*=-1.0$; Green: $\mu^*=0.0$; Red: $\mu^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\begin{figure}[htbp]
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_b1}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_b2}
		\hfill
		\includegraphics[width=0.3\textwidth,angle=0]{images/E2y_vs_y_b3}
		%\\
		%\captionsetup{width=0.5\textwidth}
		\vfill
		\parbox{0.95\textwidth}{\caption{\label{fig:E2y_vs_y_b} Quantity $E_2(T^*,\mu^*;y)$ as a function of $y$ at different values of $T^*$ and $\mu^*$. Left: $\mu^*=-1.0$; Center: $\mu^*=0.0$; Right: $\mu^*=0.5$. Lines: Navy: $T^*=0.2$; Aquamarine: $T^*=0.25$; Maroon: $T^*=0.5$.}}
		%\hfill
		%\captionsetup{width=0.5\textwidth}
		
	\end{figure}
	
	\appendix
	
	\pagebreak
	
	\section{Auxilary equalities}
	Note the following summation results:
	\begin{equation}
		\label{eq:1}
		N_l \equiv \abs{\gamma_l} = \sum_{\vb{r} \in \gamma_l} 1 = \sum_{\vb{r} \in \gamma} \mathbb{I}_{\Delta_l}(\vb{r}) = \sum_{j=1}^{N} \mathbb{I}_{\Delta_{l}}(\vb{r}_j),
	\end{equation}
	
	\begin{equation}
		\label{eq:2}
		\sum_{l=1}^{N_v} N_l = N, \quad \sum_{l=1}^{N_v} \abs{\gamma_l} = \abs{\gamma},
	\end{equation}
	\begin{equation}
		\label{eq:3}
		\left(\sum_{l=1}^{N_v} N_l \right)^2 = N^2, \quad \left(\sum_{l=1}^{N_v} \abs{\gamma_l} \right)^2 = \abs{\gamma}^2.
	\end{equation}
	\begin{equation}
		\label{eq:4}
		\sum_{\vb{r} \in \gamma} \rightarrow \sum_{l=1}^{N_v} \sum_{\vb{r} \in \Delta_l};
	\end{equation}
	\begin{equation}
		\label{eq:5}
		\sum_{\vb{r}, \vb{r}' \in \gamma} \rightarrow \sum_{l,l'=1}^{N_v} \sum_{\vb{r} \in \Delta_l} \sum_{\vb{r}' \in \Delta_{l'}}.
	\end{equation}
	\begin{equation}
		\label{eq:6}
		\sum_{\vb{r} \in \Delta_l}\sum_{\vb{r}' \in \Delta_l'} 1 = N_l N_{l'} = \abs{\gamma_l} \abs{\gamma_{l'}}.
	\end{equation}
	\begin{equation}
		\label{eq:sumII}
		\sum_{\vb{r}, \vb{r}' \in \gamma}\sum_{l=1}^{N_v} \mathbb{I}_{\Delta_l}(\vb{r}) \mathbb{I}_{\Delta_{l}}(\vb{r}') = \sum_{l=1}^{N_v} N_l^2 \equiv \sum_{l=1}^{N_v} \abs{\gamma_l}^2.
	\end{equation}
	Combining these formulas, we obtain
	\begin{eqnarray}
		\sum_{\vb{r}, \vb{r}' \in \gamma} \Phi_{N_v}(\vb{r}, \vb{r}') & = & \sum_{l,l'=1}^{N_v} \sum_{\vb{r} \in \Delta_l} \sum_{\vb{r}' \in \Delta_{l'}} \Phi_{N_v}(\vb{r}, \vb{r}')
		\nonumber\\
		& = & - \frac{J_1}{N_v} \left(\sum_{l=1}^{N_v} N_l\right)^2 + J_2\sum_{l=1}^{N_v}N_l^2
		\\
		& = & - \frac{J_1}{N_v} \left(\sum_{l=1}^{N_v} \abs{\gamma_l}\right)^2 + J_2\sum_{l=1}^{N_v}\abs{\gamma_l}^2
	\end{eqnarray}
	
	\subsection{Integration example}
	\label{subsec:int}
	In this subsection, explicit integration of the integral in~\eqref{eq:XiIntt} is present.
	
	\begin{align}
		I = & \int\limits_{0}^{1} {\rm d} t \exp[2\pi {\rm i} \varrho t + \vartheta\exp(-2\pi {\rm i}t)]
		\nonumber\\	
		= & \frac{1}{2\pi} \int\limits_{0}^{2\pi} {\rm d}x {\rm e}^{{\rm i}\varrho x} \exp(\vartheta {\rm e}^{-{\rm i}x})
		\nonumber\\
		= & \frac{1}{2\pi} \int\limits_{0}^{2\pi} {\rm d}x {\rm e}^{{\rm i}\varrho x} \sum_{n \geq 0} \frac{\vartheta^n}{n!} {\rm e}^{-{\rm i}nx}
		\nonumber\\
		= & \sum_{n \geq 0} \frac{\vartheta^n}{n!} \frac{1}{2\pi} \int\limits_{0}^{2\pi} {\rm d}x {\rm e}^{{\rm i}(\varrho - n)x}
		\nonumber\\
		= & \sum_{n \geq 0} \frac{\vartheta^n}{n!} \delta_{n\varrho} = \frac{\vartheta^{\varrho}}{\varrho!}.
	\end{align}
	In the course of calculation, we have used the change of variables $x = 2\pi t$ and the definition~\eqref{def:Kronecker} for the Kronecker $\delta$-symbol.
	
	\subsection{\label{sec:app1} Explicit derivation of $E(T^*,\mu^*;y)$ and $K_0(T^*,\mu^*;y)$}
	In this appendix, the explicit transformations from Eq.~\eqref{eq:XiPi} through~\eqref{eq:gaussInt} to~Eqs.~\eqref{eq:XiInty}, \eqref{def:E}, and~\eqref{def:K}, is presented. Substituting the Gaussian integral~\eqref{eq:gaussInt} into~\eqref{eq:XiPi}, one proceeds as follows
	\begin{eqnarray}
		\Xi 
		&=& 
		\sum_{\varrho \in \mathbb{N}_0^{N_v}} \sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty} \exp(-\frac{N_v}{2} T^* y^2) 
		\prod\limits_{l=1}^{N_v} \frac{(v^* T^{*3/2})^{\varrho_l}}{\varrho_l !} 
		\exp[\left(y + \frac{\mu^*}{T^*}\right) \varrho_l - \frac{a}{2T^*}\varrho_l^2] {\rm d}y
		\nonumber\\
		&=&
		\sqrt{\frac{N_v T^*}{2\pi}} \sum_{\varrho_1=0}^{\infty} \ldots \sum_{\varrho_{N_v}=0}^{\infty} 
		\int\limits_{-\infty}^{\infty} {\rm e}^{-N_v \frac{T^* y^2}{2}} 
		\prod\limits_{l=1}^{N_v} \frac{(v^* T^{*3/2})^{\varrho_l}}{\varrho_l !} 
		\exp[\left(y + \frac{\mu^*}{T^*}\right) \varrho_l - \frac{a}{2T^*}\varrho_l^2] {\rm d}y
		\nonumber\\
		&=&
		\sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty} {\rm e}^{-N_v \frac{T^* y^2}{2}}
		\left\{ 
			\sum_{\varrho_1=0}^{\infty} \frac{(v^* T^{*3/2})^{\varrho_1}}{\varrho_1 !} \exp[\left(y + \frac{\mu^*}{T^*}\right) \varrho_1 - \frac{a}{2T^*}\varrho_1^2] 
		\right\}
		\nonumber\\
		&& 
		\times \ldots \times 
		\left\{ 
			\sum_{\varrho_{N_v}=0}^{\infty} \frac{(v^* T^{*3/2})^{\varrho_{N_v}}}{\varrho_{N_v} !} \exp[\left(y + \frac{\mu^*}{T^*}\right) \varrho_{N_v} - \frac{a}{2T^*}\varrho_{N_v}^2] 
		\right\}
		{\rm d}y
		\nonumber\\
		&=&
		\sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty} {\rm e}^{-N_v \frac{T^* y^2}{2}}
		\exp( \ln \left\{\sum_{n=0}^{\infty} \frac{(v^* T^{*3/2})^{n}}{n!} \exp[\left(y + \frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2] \right\}^{N_v} ) {\rm d}y
		\nonumber\\
		&=&
		\sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty}
		\exp 
		\left\{ N_v 
			\left[ -\frac{T^* y^2}{2} + 
			\ln(\sum_{n=0}^{\infty} \frac{(v^* T^{*3/2})^{n}}{n!} {\rm e}^{\left(y + \frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2}) 
			\right] 
		\right\} {\rm d}y,
	\end{eqnarray}
	and arrives at Eqs.~\eqref{eq:XiInty}, \eqref{def:E}, and~\eqref{def:K}
	\begin{equation}
		\Xi = \sqrt{\frac{N_v T^*}{2\pi}} \int\limits_{-\infty}^{\infty}
		\exp 
		\left\{ N_v 
		\left[ -\frac{T^* y^2}{2} + 
		\ln K_0(T^*,\mu^*;y) 
		\right] 
		\right\} {\rm d}y.
	\end{equation}
	
	\pagebreak	
		
	\section{\label{sec:app:dens} Calculation of Density}
	This Appendix contains explicit calculation of density from~\eqref{eq:dens}. By~\eqref{eos:reduced}
	\begin{equation}
		\label{B1}
		\rho^*(T^*,\mu^*) = \frac{\partial P^*}{\partial \mu^*} = T^* \frac{\partial E(T^*,\mu^*;\bar{y}_{\rm max})}{\partial \mu^*}.
	\end{equation}
	Then from~\eqref{def:E}, it follows
%	\begin{equation}
%		\frac{\partial E}{\partial \mu^*} = \frac{1}{K_0} \frac{\partial K_0}{\partial \mu^*},
%	\end{equation}
	\begin{equation}
		\frac{\partial E}{\partial \mu^*} = -T^* \bar{y}_{\rm max} \cdot \partial_{\mu^*} \bar{y}_{\rm max} + \frac{1}{K_0} \partial_{\mu^*} K_0,
	\end{equation}
	and by~\eqref{def:K}
	%\begin{equation}
	%	\frac{\partial K_0}{\partial \mu^*} = \frac{1}{T^*}K_1.
	%\end{equation}
	\begin{equation}
		\partial_{\mu^*} K_0 = K_1\left(\frac{1}{T^*} + \partial_{\mu^*} \bar{y}_{\rm max}\right).
	\end{equation}
	In the two last equations we imply $K_i = K_i(T^*,\mu^*;\bar{y}_{\rm max})$ and use notation $\partial_{\mu^*} \equiv \partial / \partial \mu^*$.
	Substituting the found derivatives back into Eq.~\eqref{B1}, we arrive at
	\begin{eqnarray}
		\frac{\partial E}{\partial \mu^*} & = & \frac{1}{T^*} \frac{K_1}{K_0} + \left(-T^*\bar{y}_{\rm max} + \frac{K_1}{K_0}\right)\partial_{\mu^*}\bar{y}_{\rm max}
		\nonumber\\
		& = & \frac{1}{T^*} \frac{K_1}{K_0},
	\end{eqnarray}
	where we accounted for~\eqref{eq:bar_y}.
	Finally
	\begin{equation}
		\left(\frac{\partial P^*}{\partial \mu^*} \right)_T = \frac{K_1}{K_0} = \rho^*.
	\end{equation}
	
	\section{\label{sec:app:cp} System of equations for the critical point coordinates}
	In this Appendix we calculate the first and second derivatives of the pressure with respect to the density and show that setting them equal to zero results in the system of equations~\eqref{E2E3eq0}.
	
	The first derivative is derived as follows
	\begin{eqnarray}
		\left(\frac{\partial P^*}{\partial \rho^*}\right)_{T^*} & = & 
		\frac{\left(\partial P^* / \partial \mu^*\right)_{T^*}}{\left(\partial \rho^* / \partial \mu^* \right)_{T^*}}
		\nonumber\\
		& = & \frac{\rho^*(T^*,\mu^*)}{T^* \left(\partial \bar{y}_{\rm max} / \partial \mu^*\right)_{T^*}}
		\nonumber\\
		& = & - \frac{K_1}{K_0} \frac{E_2}{E_2 + T^*}.
	\end{eqnarray}
	Here, we applied Eqs.~\eqref{eq:dens}, \eqref{eq:densK}, \eqref{rho_vs_T_mu}, and~\eqref{dydm}. Since $K_i \neq 0$, and $E_2 + T^* > 0$ (see Eq.~\eqref{E2pT}), we obtain
	\begin{equation}
		\label{C2}
		\left(\frac{\partial P^*}{\partial \rho^*}\right)_{T^*} = 0 \implies E_2 = 0.
	\end{equation}
	
	Let us explicitly write out the derivatives used above and that may be useful later on:
	\begin{equation}
		\left( \frac{\partial \bar{y}_{\rm max}}{\partial \mu^*} \right)_{T^*} = -\frac{E_2 + T^*}{T^* E_2};
	\end{equation}
	\begin{equation}
		\left( \frac{\partial \rho^*}{\partial \mu^*} \right)_{T^*} = T^* \left( \frac{\partial \bar{y}_{\rm max}}{\partial \mu^*} \right)_{T^*}
		= -\frac{E_2 + T^*}{E_2}.
	\end{equation}
	
	The second derivative of the pressure with respect to density is calculated as follows
	\begin{eqnarray}
		\left(\frac{\partial^2 P^*}{\partial \rho^{*2}}\right)_{T^*} & = & -\frac{\partial}{\partial \rho^*} \left(\frac{K_1}{K_0} \frac{E_2}{E_2 + T^*} \right)_{T^*}
		\nonumber\\
		& = & -\frac{\partial}{\partial \mu^*} \left(\frac{K_1}{K_0} \frac{E_2}{E_2 + T^*} \right)_{T^*} \bigg/ \left(\frac{\partial \rho^*}{\partial \mu^*}\right)_{T^*}
		\nonumber\\
		& = & \frac{E_2}{E_2 + T^*} \left[- \frac{K_2K_0 - K_1^2}{K_0^2} \frac{1}{E_2 + T^*} + \frac{K_1}{K_0} \frac{E_3}{(E_2 + T^*)^2}\right]
		\nonumber\\
		& & - \frac{K_1}{K_0} \frac{E_3}{(E_2 + T^*)^2}
	\end{eqnarray}
	Thus, taking into account Eq.~\eqref{C2}, we conclude
	\begin{equation}
		\left(\frac{\partial^2 P^*}{\partial \rho^{*2}}\right)_{T^*} = 0 \implies E_3 = 0.
	\end{equation} 
	
	\section{\label{sec:app:entropy} Calculation of Entropy}
	This Appendix contains explicit calculation of entropy from Eq.~\eqref{eq:entropy} by taking derivatives of pressure with respect to temperature
	\begin{equation}
		S^{*} = \frac{1}{\rho^*} \left[E + T^* \left(\frac{\partial E}{\partial T^*}\right)_{\mu^*}\right];
	\end{equation}
	\begin{equation}
		E = -\frac{1}{2}T^* \bar{y}_{\rm max}^2 + \ln K_0.
	\end{equation}
	\begin{equation}
		\frac{\partial E}{\partial T^*} = -\frac{1}{2}\bar{y}_{\rm max}^2 - T^* \bar{y}_{\rm max} \frac{\partial \bar{y}_{\rm max}}{\partial T^*} + \frac{1}{K_0}\frac{\partial}{\partial T^*} K_0.
	\end{equation}
	\begin{eqnarray}
		\frac{\partial K_0}{\partial T^*} & = & \sum_{n=0}^{\infty} \frac{n v^*(v^* T^{*3/2})^{n-1}}{n!} \frac{3T^{*1/2}}{2}\exp(F_n) 
		\nonumber\\
		& + & \sum_{n=0}^{\infty} \frac{(v^* T^{*3/2})^n}{n!} \exp(F_n) \frac{\partial}{\partial T^*} F_n,
	\end{eqnarray}
	where we temporary introduced
	\begin{eqnarray*}
		F_n & = & \left(\bar{y}_{\rm max} + \frac{\mu^*}{T^*} \right)n -\frac{a}{2T^*}n^2.
	\end{eqnarray*}
	The derivative of $F_n$ with respect to $T^*$ is
	\begin{equation}
		\frac{\partial F_n}{\partial T^*} = -\frac{1}{T^*} \left(\frac{\mu^*}{T^*}n - \frac{a}{2T^*}n^2\right) + n \frac{\partial \bar{y}_{\rm max}}{\partial T^*}.
	\end{equation}
	Substituting the last result into the derivative for $K_0$, we get
	\begin{equation}
		\frac{\partial K}{\partial T^*} = \frac{1}{T^*} \left(\frac{3}{2} - \frac{\mu^*}{T^*} \right)K_1 + \frac{1}{T^*}\frac{a}{2 T^*} K_2 + K_1 \frac{\partial \bar{y}_{\rm max}}{\partial T^*}.
	\end{equation}
	For the derivative of $E$ with respect to $T^*$ we have
	\begin{eqnarray}
		\frac{\partial E}{\partial T^*} & = & -\frac{1}{2}\bar{y}_{\rm max}^2 + \frac{1}{T^* K_0} \left[\left(\frac{3}{2} - \frac{\mu^*}{T^*} \right)K_1 + \frac{a}{2 T^*} K_2\right] + \left(-T^*\bar{y} + \frac{K_1}{K_0}\right) \frac{\partial \bar{y}_{\rm max}}{\partial T^*}
		\nonumber\\
		& = & -\frac{1}{2}\bar{y}_{\rm max}^2 + \frac{1}{T^* K_0} \left[\left(\frac{3}{2} - \frac{\mu^*}{T^*} \right)K_1 + \frac{a}{2 T^*} K_2\right],
	\end{eqnarray}
	where we accounted for~\eqref{eq:bar_y}.
	
	The final result for the entropy per particle is
	\begin{eqnarray}
		S^{*} & = & \frac{1}{\rho^*} \left\{ -T^* \bar{y}_{\rm max}^2 + \ln K_0 + \frac{1}{K_0} \left[\left(\frac{3}{2} - \frac{\mu^*}{T^*} \right)K_1 + \frac{a}{2 T^*} K_2\right] \right\}
		\\
		& = & \frac{1}{\rho^*} \left\{ -\frac{1}{T^*} \frac{K_1^2}{K_0^2} + \ln K_0 + \frac{1}{K_0} \left[\left(\frac{3}{2} - \frac{\mu^*}{T^*} \right)K_1 + \frac{a}{2 T^*} K_2\right] \right\}.
	\end{eqnarray}
	Taking into account~\eqref{eq:densK}, we finally get
	\begin{equation}
		S^* = \left(\frac{3}{2} - \frac{\mu^*}{T^*}\right) - \frac{1}{T^*}\frac{K_1}{K_0} + \frac{K_0 \ln K_0}{K_1} + \frac{a}{2T^*} \frac{K_2}{K_1}.
	\end{equation}
	
	Note that we may have ignored here the dependence of $\bar{y}_{\rm max}$ on temperature, since $\bar{y}_{\rm max}$ maximizes $E$ and thus the contribution of partial derivative of $E$ with respect to $\bar{y}_{\rm max}$ will be zero. However, such dependence must be accounted when calculating higher order derivatives, e.g. when calculating the heat capacity $C_V$.
	
	\pagebreak
	\section{Relations for special functions}
	\subsection{Special functions $K_i$}
	\textbf{Definitions.}
	
	Generic definition is as follows
	\begin{equation}
		K_i(T^*,\mu^*;y) = \sum_{n=0}^{\infty} \frac{n^i (v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2].
	\end{equation}
	
	Explicit expressions for a few first $i$-s are as follows
	\begin{equation}
		K_0(T^*,\mu^*;y) = \sum_{n=0}^{\infty} \frac{(v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2];
	\end{equation}
	\begin{equation}
		K_1(T^*,\mu^*;y) = \sum_{n=0}^{\infty} \frac{n(v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2];
	\end{equation}
	\begin{equation}
		K_2(T^*,\mu^*;y) = \sum_{n=0}^{\infty} \frac{n^2 (v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2];
	\end{equation}
	\begin{equation}
		K_3(T^*,\mu^*;y) = \sum_{n=0}^{\infty} \frac{n^3 (v^* T^{*3/2})^n}{n!} \exp[\left(y+\frac{\mu^*}{T^*}\right)n - \frac{a}{2T^*}n^2].
	\end{equation}
	
	\textbf{Partial derivatives with respect to $y$.} 
	\begin{equation}
		\frac{\partial K_n(T^*,\mu^*;y)}{\partial y}\bigg|_{(T^*,\mu^*)} = K_{n+1}(T^*,\mu^*;y),
	\end{equation}
	and thus
	\begin{eqnarray}
		K_n(T^*,\mu^*;y) & = & \frac{\partial K_{n-1}(T^*,\mu^*;y)}{\partial y} \bigg|_{(T^*,\mu^*)}
		\nonumber\\
		& = & \frac{\partial^n K_{0}(T^*,\mu^*;y)}{\partial y^n} \bigg|_{(T^*,\mu^*)}.
	\end{eqnarray}
	
	\textbf{Partial derivatives with respect to $\mu^*$.}
	\begin{equation}
		\frac{\partial K_n(T^*,\mu^*;y)}{\partial \mu^*} \bigg|_{(T^*,y)} = \frac{1}{T^*} K_{n+1}(T^*,\mu^*;y).
	\end{equation}
	
	\textbf{Partial derivatives with respect to $T^*$.}
	\begin{equation}
		\frac{\partial K_n(T^*,\mu^*;y)}{\partial T^*} \bigg|_{(\mu^*,y)} = \frac{1}{T^*} \left(\frac{3}{2} - \frac{\mu^*}{T^*}\right) K_{n+1}(T^*,\mu^*;y).
	\end{equation}
	
	If we do not consider $y$ as an independent variable, but rather as a function of other two variables, $T^*$ and $\mu^*$, we rewrite the derivatives as follows. We use notation $\bar{y}$ here by analogy with the point of extremum for $E$, see Section~\ref{sec:pres}
	
	Partial derivatives with respect to $\mu^*$ become
	\begin{eqnarray}
		\frac{\partial K_n(T^*,\mu^*;\bar{y})}{\partial \mu^*} \bigg|_{T^*} & = & \left(\frac{1}{T^*} + \frac{\partial \bar{y}}{\partial \mu^*}\bigg|_{T^*} \right)K_{n+1}(T^*,\mu^*;\bar{y})
		\nonumber\\
		& = & 
		-\frac{1}{E_2} K_{n+1}(T^*,\mu^*;\bar{y}).
	\end{eqnarray}
	
	Partial derivatives with respect to $T^*$ become
		\begin{equation}
		\frac{\partial K_n(T^*,\mu^*;\bar{y})}{\partial T^*} \bigg|_{\mu^*} = \frac{1}{T^*} \left(\frac{3}{2} - \frac{\mu^*}{T^*} + T^* \frac{\partial \bar{y}}{\partial T^*}\bigg|_{\mu^*}\right) K_{n+1}(T^*,\mu^*;\bar{y}).
	\end{equation}
	
	\subsection{Quantities $E_i$}
	It is useful to summarize similar relations for quantities $E$, $E_1$, $E_2$, and $E_3$.
	\linebreak
	\textbf{Definitions.}
	\begin{equation}
		E(T^*,\mu^*;y) = -\frac12T^*y^2 + \ln K_0;
	\end{equation}
	\begin{equation}
		E_1(T^*,\mu^*;y) = -T^* y + \frac{K_1}{K_0};
	\end{equation}
	
	\begin{equation}
		E_2(T^*,\mu^*;y) = -T^* + \frac{K_2 K_0 - K_1^2}{K_0^2};
	\end{equation}
	
	\begin{equation}
		E_3(T^*,\mu^*;y) = \frac{K_3}{K_0} - \frac{3 K_2 K_1}{K_0^2} + \frac{2K_1^3}{K_0^3}.
	\end{equation}
	
	\textbf{Partial derivatives with respect to $\mu^*$.}
	\begin{equation}
		\frac{\partial E(T^*,\mu^*;y)}{\partial \mu^*} \bigg|_{(T^*,y)} = \frac{1}{T^*}\frac{K_1}{K_0};
	\end{equation}
	
	\begin{eqnarray}
		\frac{\partial E_1(T^*,\mu^*;y)}{\partial \mu^*} \bigg|_{(T^*,y)} & = & \frac{1}{T^*} \frac{K_2 K_0 - K_1^2}{K_0^2}
		\nonumber\\
		& = & \frac{1}{T^*} \left(E_2 + T^*\right).
	\end{eqnarray}
	
	\begin{equation}
		\frac{\partial E_2(T^*,\mu^*;y)}{\partial \mu^*} \bigg|_{(T^*,y)} = \frac{1}{T^*} E_3.
	\end{equation}
	
	In the case when $y$ is not an independent variable, but a function of $T^*$ and $\mu^*$ (e.g. the one that gives an extremum to $E$), we can rewrite the quantity $E$ taking into account Eq.~\eqref{eq:bar_y}:
	\begin{equation}
		E(T^*,\mu^*;\bar{y}) = -\frac{1}{2T^*}\frac{K_1^2}{K_0^2} + \ln K_0.
	\end{equation}
	The partial derivative of $E$ with respect to $\mu^*$ becomes
	\begin{eqnarray}
		\frac{\partial E(T^*,\mu^*;\bar{y})}{\partial \mu^*} \bigg|_{T^*}
		& = & \frac{1}{T^*} \frac{K_1}{K_0} + \left( -T^*\bar{y} + \frac{K_1}{K_0} \right) \left(\frac{\partial\bar{y}}{\partial \mu^*}\right)_{T^*} 
		\nonumber\\
		& = & \frac{1}{T^*} \frac{K_1}{K_0},
	\end{eqnarray}
	where the last line simplification is valid if $\bar{y}$ is the point of extremum for $E$, see Eqs.~\eqref{cond:extr}--\eqref{eq:bar_y}.
	
	The partial derivative of $E_1$ with respect to $\mu^*$ becomes
	\begin{eqnarray}
		\frac{\partial E_1(T^*,\mu^*;\bar{y})}{\partial \mu^*} \bigg|_{T^*} & = & \frac{1}{T^*} \frac{K_2 K_0 - K_1^2}{K_0^2} + \left(-T^* + \frac{K_2 K_0 - K_1^2}{K_0^2}\right) \left(\frac{\partial\bar{y}}{\partial \mu^*}\right)_{T^*}
		\nonumber\\
		& = & \frac{E_2 + T^*}{T^*} - E_2 \frac{E_2 + T^*}{T^* E_2} = 0,
	\end{eqnarray}
	where, again, the last line simplification is valid if $\bar{y}$ is the point of extremum for $E$, see Eqs.~\eqref{cond:extr}--\eqref{eq:bar_y}.
	
	The partial derivative of $E_2$ with respect to $\mu^*$ becomes
	\begin{eqnarray}
		\frac{\partial E_2(T^*,\mu^*;\bar{y})}{\partial \mu^*} \bigg|_{T^*} & = &
		\left[\frac{1}{T^*} + \left(\frac{\partial\bar{y}}{\partial \mu^*}\right)_{T^*}\right] E_3
		\nonumber\\
		& = & \left(\frac{1}{T^*} - \frac{E_2 + T^*}{T^* E_2}\right) E_3
		\nonumber\\
		& = & -\frac{E_3}{E_2}
	\end{eqnarray}
	
	\section{Entropy: qualitative behavior}
	To understand how entropy should behave qualitatively, we will study two simple cases in this appendix, namely, the van der Waals fluid and the ideal gas.
	
	\subsection{Entopy of the van der Waals fluid}
	The entropy of the van der Waals (vdW) fluid is expressed via density and temperature as~\cite[(55)]{Johnston14}
	\begin{equation}
		\label{vdw:S}
		\frac{S}{N k_{\rm B}} = \ln \left[x_c\hat{\tau}^{3/2}(3-\hat{n})/\hat{n}\right] + \frac{5}{2},
	\end{equation}
	where $\hat{\tau} = T/T_c$, $\hat{n} = \rho/\rho_c$, and 
	\begin{equation}
		x_c \equiv \frac{k_{\rm B} T_c}{8P_c \Lambda^3_c} = \frac{b}{\Lambda^3_c},
	\end{equation}
	where $\Lambda_c$ is the de Broglie wavelength at the critical temperature, and $b$ is the ``excluded volume'' parameter of the van der Waals theory. The meaning of $b/\Lambda^3$ is similar to the meaning of quantity $v^*$ in our cell theory. To get graphical results, we put $x_c = b/\Lambda_c^3 = 5.0$.
	
	From~\eqref{vdw:S}, we can get behavior of how entropy per particle depends on density at a given temperature, see Fig.~\ref{fig:vdw_S_vs_t}, and on temperature at a given density, see Fig.~\ref{fig:vdw_S_vs_n}. 
	
	\begin{figure}[htbp]
		\includegraphics[width=0.4\textwidth,angle=0]{vdw_S_vs_t}
		\hfill
		\includegraphics[width=0.4\textwidth,angle=0]{vdw_S_vs_n}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:vdw_S_vs_t} Entropy per particle $S^{*}$ of the vdW fluid as a function of temperature $\hat{\tau}$ at a given density. (Dashed black line): $\hat{n}=0.5$, (Solid blue line): $\hat{n}=1.0$, and (Dash-dotted green line): $\hat{n}=1.5$.}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:vdw_S_vs_n} Entropy per particle $S^{*}$ of the vdW fluid as a function of density $\hat{n}$ at a given temperature. (Dashed black line): $\hat{\tau}=0.5$, (Solid blue line): $\hat{\tau}=1.0$, and (Dash-dotted green line): $\hat{\tau}=2.0$.}}
	\end{figure}
	
	The chemical potential of the vdW fluid is given by~\cite[(70c)]{Johnston14}
	\begin{equation}
		\label{vdw:mu}
		\frac{\mu}{k_{\rm B}T_c} = -\hat{\tau} \ln \left(\frac{3-\hat{n}}{\hat{n}}\right) + \frac{\hat{\tau}\hat{n}}{3-\hat{n}} - \frac{9\hat{n}}{4} - \hat{\tau}\ln(\hat{\tau}^{3/2}) - \hat{\tau}\ln(x_c).
	\end{equation}
	Considering Eqs.~\eqref{vdw:mu} and~\eqref{vdw:S} together as parametric equation, we can plot dependence of entropy on chemical potential at a given temperature, see Fig.~\ref{fig:vdw_S_vs_mu}.
	
	\begin{figure}[htbp]
		\includegraphics[width=0.45\textwidth,angle=0]{vdw_S_vs_mu}
		\hfill
		\includegraphics[width=0.45\textwidth,angle=0]{vdw_S_vs_t_at_mu}
		\\
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:vdw_S_vs_mu} Entropy per particle $S^{*}$ of the vdW fluid as a function of chemical potential $\mu/(k_{\rm B}T_c)$ at a given temperature, (Dashed black line): $\hat{\tau}=0.5$, (Solid blue line): $\hat{\tau}=1.0$, (Dash-dotted green line): $\hat{\tau}=1.5$.}}
		\hfill
		%\captionsetup{width=0.5\textwidth}
		\parbox{0.45\textwidth}{\caption{\label{fig:vdw_S_vs_t_at_mu} Entropy per particle $S^{*}$ of the vdW fluid as a function of temperature $\hat{\tau}$ at a given chemical potential $\mu/(k_{\rm B}T_c) = -6.0$.}}
	\end{figure}
	
	\pagebreak
	\include{./notation}
	
	%\include{./asymptotics}

	\pagebreak	
	%\bibliographystyle{elsarticle-num}
	\bibliographystyle{gost2008}
	\bibliography{books,articles}
	
\end{document}